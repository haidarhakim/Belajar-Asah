{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXj2u7Kxi3kVgj1HowsZKw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haidarhakim/Belajar-Asah/blob/main/Proyek_Sentimen_Adhan_Haidar_Hakim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N4DqlVgGGbK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n"
      ],
      "metadata": {
        "id": "_dLwGYGNGvqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-play-scraper pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrsl4DnQPWif",
        "outputId": "397724df-7247-484d-e7e8-ec55289ddb80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google_play_scraper import Sort, reviews\n",
        "\n",
        "# Mengambil ulasan dari aplikasi Honor of Kings\n",
        "result, continuation_token = reviews(\n",
        "    'com.levelinfinite.sgameGlobal',\n",
        "    lang='id',                # Bahasa ulasan (Indonesia)\n",
        "    country='id',             # Negara (Indonesia)\n",
        "    sort=Sort.NEWEST,         # Mengurutkan berdasarkan ulasan terbaru\n",
        "    count=20000,              # Jumlah ulasan yang ingin diambil\n",
        "    filter_score_with=None    # Mengambil semua skor rating\n",
        ")\n",
        "\n",
        "# Membuat DataFrame dari hasil scraping\n",
        "df = pd.DataFrame(result)\n",
        "\n",
        "# Menyimpan DataFrame ke dalam file CSV\n",
        "df.to_csv('honor_of_kings_reviews.csv', index=False)\n",
        "\n",
        "print(\"Scraping selesai. Data tersimpan dalam file 'honor_of_kings_reviews.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxh892lDQDdG",
        "outputId": "bd8728b8-039c-45a5-8aad-a894f04c7c47"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping selesai. Data tersimpan dalam file 'honor_of_kings_reviews.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pelatihan Model\n"
      ],
      "metadata": {
        "id": "CFffI7VbQv8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn nltk sastrawi gensim tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsX7ccDWQyzN",
        "outputId": "b06e9aa4-831c-41bb-af8b-f3d590b99372"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: sastrawi in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Muat dataset\n",
        "df = pd.read_csv('honor_of_kings_reviews.csv')\n",
        "\n",
        "# Menampilkan 5 baris pertama data\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLf9ct6TQ9mN",
        "outputId": "7d7fcda5-51f4-454d-dee2-c83f793b60f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               reviewId         userName  \\\n",
            "0  76cc1fd7-e7bb-4f2f-a530-8e2f2c0d15ff  Pengguna Google   \n",
            "1  f975780d-55c8-442f-bc3a-30424d026371  Pengguna Google   \n",
            "2  da802bdc-34b9-4066-8149-4ae5de585640  Pengguna Google   \n",
            "3  c2fb643f-88db-4bc6-a239-116097c1ea67  Pengguna Google   \n",
            "4  aa8344d9-cd6f-49cc-be45-59e4a6dc8fb1  Pengguna Google   \n",
            "\n",
            "                                           userImage  \\\n",
            "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "\n",
            "                                             content  score  thumbsUpCount  \\\n",
            "0                                       gemnya haram      1              0   \n",
            "1                  sinyal full main tp mesti nge lag      1              0   \n",
            "2                              game buruk mending ml      1              0   \n",
            "3  gila cuy keren nih game cuma kalo buat hp kent...      5              0   \n",
            "4  pengen download lagi tapi memori ku gak cukup ...      5              0   \n",
            "\n",
            "  reviewCreatedVersion                   at  \\\n",
            "0                  NaN  2025-10-06 10:06:33   \n",
            "1                  NaN  2025-10-06 09:48:28   \n",
            "2                  NaN  2025-10-06 09:38:25   \n",
            "3                  NaN  2025-10-06 09:36:35   \n",
            "4                  NaN  2025-10-06 09:14:02   \n",
            "\n",
            "                                        replyContent            repliedAt  \\\n",
            "0  Hai pemain, \\nMohon maaf atas ketidakpuasan ya...  2025-10-06 11:47:51   \n",
            "1  Hai pemain, \\nKami memahami perasaanmu. Jika s...  2025-10-06 11:47:36   \n",
            "2                                                NaN                  NaN   \n",
            "3                                                NaN                  NaN   \n",
            "4                                                NaN                  NaN   \n",
            "\n",
            "  appVersion  \n",
            "0        NaN  \n",
            "1        NaN  \n",
            "2        NaN  \n",
            "3        NaN  \n",
            "4        NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk membersihkan teks\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()  # Mengubah teks menjadi huruf kecil\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Menghapus karakter selain huruf dan spasi\n",
        "        return text\n",
        "    return \"\"\n",
        "\n",
        "# Membersihkan kolom 'content'\n",
        "df['cleaned_content'] = df['content'].apply(clean_text)\n",
        "\n",
        "# Fungsi untuk pelabelan sentimen\n",
        "def label_sentiment(score):\n",
        "    if score >= 4:\n",
        "        return 'positif'\n",
        "    elif score == 3:\n",
        "        return 'netral'\n",
        "    else:\n",
        "        return 'negatif'\n",
        "\n",
        "# Membuat kolom sentimen\n",
        "df['sentiment'] = df['score'].apply(label_sentiment)\n",
        "\n",
        "# Menghapus baris dengan teks kosong setelah pembersihan\n",
        "df = df[df['cleaned_content'] != '']\n",
        "\n",
        "# Menampilkan distribusi sentimen\n",
        "print(df['sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BtWy2MfRFAW",
        "outputId": "403ffd54-2323-41ec-bb88-6f70ecb13960"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "positif    12198\n",
            "negatif     6387\n",
            "netral      1224\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ekstraksi fitur dan pembagian data\n",
        "\n",
        "# Inisialisasi stop words Bahasa Indonesia\n",
        "stop_words = set(stopwords.words('indonesian'))\n",
        "\n",
        "# Ekstraksi Fitur dengan TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=list(stop_words))\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_content'])\n",
        "\n",
        "# Memisahkan fitur (X) dan label (y)\n",
        "y = df['sentiment']\n",
        "\n",
        "# Pembagian data (akan disesuaikan untuk setiap skema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlmMFINhRKl_",
        "outputId": "779c0298-5bb2-4f30-839f-60304e9b19da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skema 1: SVM, TF-IDF 70/30"
      ],
      "metadata": {
        "id": "icC7uQ1ry3Fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pembagian data 80/20\n",
        "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pelatihan model SVM\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train_1, y_train_1)\n",
        "\n",
        "# Prediksi pada data uji\n",
        "y_pred_1 = svm_model.predict(X_test_1)\n",
        "\n",
        "# Evaluasi model\n",
        "accuracy_1 = accuracy_score(y_test_1, y_pred_1)\n",
        "print(f\"Akurasi Skema 1 (SVM, TF-IDF, 80/20): {accuracy_1:.2f}\")\n",
        "print(classification_report(y_test_1, y_pred_1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf9bk1cnROb9",
        "outputId": "8879f383-ebee-4c98-bd4d-0d32b434cd63"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Skema 1 (SVM, TF-IDF, 70/30): 0.80\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.73      0.75      0.74      1927\n",
            "      netral       0.00      0.00      0.00       354\n",
            "     positif       0.83      0.90      0.87      3662\n",
            "\n",
            "    accuracy                           0.80      5943\n",
            "   macro avg       0.52      0.55      0.53      5943\n",
            "weighted avg       0.75      0.80      0.77      5943\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skema 2: Random FOrest, Word2Vec, 80/20"
      ],
      "metadata": {
        "id": "gxBNt3OCR8GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pelatihan model Random Forest\n",
        "rf_model_1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model_1.fit(X_train_2, y_train_2)\n",
        "\n",
        "# Prediksi pada data uji\n",
        "y_pred_2 = rf_model_1.predict(X_test_2)\n",
        "\n",
        "# Evaluasi model\n",
        "accuracy_2 = accuracy_score(y_test_2, y_pred_2)\n",
        "print(f\"Akurasi Skema 2 (RF, TF-IDF, 80/20): {accuracy_2:.2f}\")\n",
        "print(classification_report(y_test_2, y_pred_2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jB55ThTR9RO",
        "outputId": "187b817f-12db-4dda-a47c-5e3393259b36"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Skema 2 (RF, TF-IDF, 80/20): 0.79\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.71      0.75      0.73      1283\n",
            "      netral       0.14      0.00      0.01       250\n",
            "     positif       0.83      0.89      0.86      2429\n",
            "\n",
            "    accuracy                           0.79      3962\n",
            "   macro avg       0.56      0.55      0.53      3962\n",
            "weighted avg       0.75      0.79      0.76      3962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skema 3: Random Forest, TF-IDF 80/20\n"
      ],
      "metadata": {
        "id": "-hDoq-dwSFLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pembagian data 70/30\n",
        "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pelatihan model Random Forest\n",
        "rf_model_2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model_2.fit(X_train_3, y_train_3)\n",
        "\n",
        "# Prediksi pada data uji\n",
        "y_pred_3 = rf_model_2.predict(X_test_3)\n",
        "\n",
        "# Evaluasi model\n",
        "accuracy_3 = accuracy_score(y_test_3, y_pred_3)\n",
        "print(f\"Akurasi Skema 3 (RF, TF-IDF, 70/30): {accuracy_3:.2f}\")\n",
        "print(classification_report(y_test_3, y_pred_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brav5HbfSJJ2",
        "outputId": "6a2f230e-65cf-4713-9dd7-11d6ddddb494"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Skema 3 (RF, TF-IDF, 70/30): 0.79\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.71      0.75      0.73      1283\n",
            "      netral       0.14      0.00      0.01       250\n",
            "     positif       0.83      0.89      0.86      2429\n",
            "\n",
            "    accuracy                           0.79      3962\n",
            "   macro avg       0.56      0.55      0.53      3962\n",
            "weighted avg       0.75      0.79      0.76      3962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh ulasan baru\n",
        "new_review = \"Game sampah!\"\n",
        "\n",
        "# Preprocessing ulasan baru\n",
        "cleaned_review = clean_text(new_review)\n",
        "\n",
        "# Transformasi dengan TF-IDF Vectorizer yang sudah dilatih\n",
        "vectorized_review = tfidf_vectorizer.transform([cleaned_review])\n",
        "\n",
        "# Prediksi sentimen menggunakan model terbaik (misalnya SVM)\n",
        "predicted_sentiment = svm_model.predict(vectorized_review)\n",
        "\n",
        "print(f\"Ulasan: '{new_review}'\")\n",
        "print(f\"Prediksi Sentimen: {predicted_sentiment[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvmy0GPxzipA",
        "outputId": "1912e083-7253-41f2-8465-58015f5dc239"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ulasan: 'Game sampah!'\n",
            "Prediksi Sentimen: negatif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ini mau nyoba 1 doang dah sek..\n",
        "import pandas as pd\n",
        "import re\n",
        "from google_play_scraper import Sort, reviews\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Scraping Data\n",
        "result, _ = reviews(\n",
        "    'com.levelinfinite.sgameGlobal',\n",
        "    lang='id',\n",
        "    country='id',\n",
        "    sort=Sort.NEWEST,\n",
        "    count=700000\n",
        ")\n",
        "df = pd.DataFrame(result)\n",
        "\n",
        "# 2. Preprocessing dan Pelabelan\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        return text\n",
        "    return \"\"\n",
        "\n",
        "def label_sentiment(score):\n",
        "    if score >= 4:\n",
        "        return 'positif'\n",
        "    elif score == 3:\n",
        "        return 'netral'\n",
        "    else:\n",
        "        return 'negatif'\n",
        "\n",
        "df['cleaned_content'] = df['content'].apply(clean_text)\n",
        "df['sentiment'] = df['score'].apply(label_sentiment)\n",
        "df = df[df['cleaned_content'] != '']\n",
        "\n",
        "# 3. Ekstraksi Fitur dan Pembagian Data\n",
        "tfidf = TfidfVectorizer(max_features=3000)\n",
        "X = tfidf.fit_transform(df['cleaned_content'])\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Pelatihan Model\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluasi\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Akurasi Model: {accuracy:.2f}\")\n",
        "\n",
        "# 6. Inference\n",
        "new_review = \"Gamenya jelek, sering nge-lag.\"\n",
        "cleaned_review = clean_text(new_review)\n",
        "vectorized_review = tfidf.transform([cleaned_review])\n",
        "predicted_sentiment = model.predict(vectorized_review)\n",
        "print(f\"Prediksi untuk '{new_review}': {predicted_sentiment[0]}\")\n",
        "\n",
        "#ini terpaksa ga tak jalanin karna 1 jam setengah, aganya nyesel bang nyoba:"
      ],
      "metadata": {
        "id": "4VE8DOajzw8G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}